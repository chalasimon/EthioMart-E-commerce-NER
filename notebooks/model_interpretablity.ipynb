{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seqeval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXav55zltEXb",
        "outputId": "826ee9e5-013f-46f7-9391-3541be4d882a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kduw4DcRsK7I"
      },
      "outputs": [],
      "source": [
        "# loading the libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import Dataset, Features, Value, ClassLabel\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import numpy as np\n",
        "import logging\n",
        "from itertools import chain\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset,concatenate_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lE5Bu2xGxoiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the models\n",
        "MODEL_NAME= \"/content/drive/MyDrive/week4/model/xlm-roberta-model\""
      ],
      "metadata": {
        "id": "sekIA8uet0kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_1)\n",
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "3EgLFm4wwC7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"ሞብ ጎማ የተገጠመለት ተጨማሪ ቅያሪ ጨርቅ ያለው የራሱ ዉሀ ማፍሰሻ የተገጠመለት ዋጋ 3000 ብር\"\n",
        "tokens = sentence.split()"
      ],
      "metadata": {
        "id": "E7p4G70MwM2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, truncation=True)\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits  # [1, seq_len, num_labels]\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "predictions = torch.argmax(probabilities, dim=-1)"
      ],
      "metadata": {
        "id": "pD3eAsDTwQTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret\n",
        "for i, token in enumerate(tokens):\n",
        "    input_ids = inputs.input_ids[0]\n",
        "    word_ids = inputs.word_ids(batch_index=0)\n",
        "    for j, word_id in enumerate(word_ids):\n",
        "        if word_id == i:\n",
        "            pred_label = model.config.id2label[predictions[0][j].item()]\n",
        "            confidence = probabilities[0][j][predictions[0][j]].item()\n",
        "            print(f\"Token: {token}\\t→ Label: {pred_label}\\t({confidence:.2f} confidence)\")"
      ],
      "metadata": {
        "id": "yQ7iwmNFyDu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}