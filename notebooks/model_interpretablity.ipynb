{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kduw4DcRsK7I"
      },
      "outputs": [],
      "source": [
        "# loading the libraries\n",
        "\n",
        "import shap\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from captum.attr import IntegratedGradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE5Bu2xGxoiW"
      },
      "outputs": [],
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sekIA8uet0kG"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_path = \"/content/drive/MyDrive/week4/model/xlm-roberta-model\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EgLFm4wwC7Z"
      },
      "outputs": [],
      "source": [
        "ner_pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_ner_counts(texts):\n",
        "    predictions = []\n",
        "    for text in texts:\n",
        "        try:\n",
        "            preds = ner_pipe(text)\n",
        "            num_entities = len(preds)\n",
        "            predictions.append([num_entities])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing: {text} => {e}\")\n",
        "            predictions.append([0])\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(predict_ner_counts, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7p4G70MwM2i"
      },
      "outputs": [],
      "source": [
        "# Example sentence\n",
        "sentence = \"ሞብ ጎማ የተገጠመለት ተጨማሪ ቅያሪ ጨርቅ ያለው የራሱ ዉሀ ማፍሰሻ የተገጠመለት ዋጋ 3000 ብር\"\n",
        "print(\"Generating SHAP value...\")\n",
        "shap_values = explainer(sentence)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
